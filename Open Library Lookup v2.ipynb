{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2142962f",
   "metadata": {},
   "source": [
    "# Do the Initalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be0c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from win10toast import ToastNotifier\n",
    "headers = {\"Accept\": \"application/json\"}\n",
    "dict = {}\n",
    "dict['notfound isbn'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ca538",
   "metadata": {},
   "source": [
    "# Import an Excel file, saved directly from Alma Analytics\n",
    "\n",
    "# Note:\n",
    "- Report from Alma Analytics has two rows that aren't needed (the title of the report and a blank row), this script skips those two rows on import\n",
    "- The report I use is set up to add quotes around the MMS IDs so that Excel doesn't cut them off by thinking it needs to put them in Scientific Notation. This script removes the quotes and sets the type as string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in input file from Analytics export\n",
    "name = input('Name of input Excel file, without extension: ')\n",
    "df = pd.read_excel(name + '.xlsx')\n",
    "\n",
    "#Loads input file, sets column headers as 2nd row of the sheet\n",
    "df.columns = df.iloc[1]\n",
    "df = df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "#Removes duplicates\n",
    "df.drop_duplicates(subset='isbn', inplace=True)\n",
    "\n",
    "#Removes string-preserving \"s\n",
    "df['isbn'] = df['isbn'].str.replace(\"\\\"\",\"\")\n",
    "\n",
    "#Reindexes again because dropping duplicates messed up the index \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd7774",
   "metadata": {},
   "source": [
    "# Grabs the ISBNs from the report and makes them a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10040dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Makes list from df column\n",
    "ISBNs = df['isbn']\n",
    "print(ISBNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0df4d98",
   "metadata": {},
   "source": [
    "# Runs each ISBN from previous step through the Open Library API\n",
    "(Saves the ISBNs that returned no results to a new list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e8be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop to run the ISBNs through the API and add ones with no returned data to a Dictionary\n",
    "for i, isbn in enumerate(ISBNs, 0):\n",
    "    #sleep(randint(5,10))    \n",
    "    isbn = ISBNs[i]    \n",
    "    getdata = requests.get('http://openlibrary.org/api/volumes/brief/isbn/' + isbn + '.json', headers=headers).json()\n",
    "    datadump = json.dumps(getdata)\n",
    "    results=json.loads(datadump)\n",
    "    \n",
    "    #If the returned results are empty (False) then add ISBN to dictionary\n",
    "    if bool(results) == False:\n",
    "        dict['notfound isbn'].append(isbn)\n",
    "\n",
    "#Prints dictionary to make sure results make sense\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d576d5c",
   "metadata": {},
   "source": [
    "# Makes a second Dataframe (for ISBNs with no matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4828b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Makes new dataframe from newly-filled dictionary, renames column and sets index\n",
    "df2 = pd.DataFrame(dict['notfound isbn'])\n",
    "df2.columns = ['not found isbn']\n",
    "df2.set_index(['not found isbn'], inplace=True)\n",
    "df.set_index(['isbn'], inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23843bde",
   "metadata": {},
   "source": [
    "# Matches second Dataframe against first, full information for the items not found in Open Library is saved to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1287c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks against original dataframe and spits out data for the ones from the \"not found\" list\n",
    "df_merged = df2.join(df, how='left', lsuffix=\"left\", rsuffix=\"right\")\n",
    "df_merged.head()\n",
    "df_merged.to_excel('Books for Open Library.xlsx') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "cee30c01e783d5135477afd5fc71078cc93d960e58c9241d5056543a778ce977"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
